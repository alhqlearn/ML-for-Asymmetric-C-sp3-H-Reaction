{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82OYBu-qqlUF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('Set-1.csv')  # Put the Out-of-Bag file name here \n",
    "df2 = pd.read_csv('Set-2.csv')\n",
    "df3 = pd.read_csv('Set-3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "7omikff7qlxk",
    "outputId": "6f472b3a-ae19-45b2-becf-394f2183af84"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "from IPython.display import HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler    \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dropout\n",
    "import csv\n",
    "import concurrent.futures\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "df=pd.read_csv('MLS-LA-LB-LC-LD-Real-Synthetic80svm.csv') #add (real plus synthetic) datafile name here\n",
    "\n",
    "#separate the real and synthetic dataset\n",
    "Real =df.iloc[:240, :]\n",
    "Synthetic =df.iloc[240:, :]\n",
    "\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(0)      \n",
    "        self.regressor = nn.Sequential(\n",
    "        nn.Linear(153, 33),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(33,150),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(150,400),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(400,168),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(168,128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 1)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.regressor(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def multNNoob(seed, df1, df2, oob1, oob2, oob3):\n",
    "    df_concat=pd.concat([df1, df2], axis=0)\n",
    "    feature=df_concat.iloc[:, :-1].values\n",
    "    output=df_concat.iloc[:, -1].values\n",
    "    \n",
    "    X_test1=oob1.iloc[:, :-1].values\n",
    "    y_test1=oob1.iloc[:, -1].values\n",
    "\n",
    "    X_test2=oob2.iloc[:, :-1].values\n",
    "    y_test2=oob2.iloc[:, -1].values\n",
    "\n",
    "\n",
    "    X_test3=oob3.iloc[:, :-1].values\n",
    "    y_test3=oob3.iloc[:, -1].values\n",
    "    \n",
    "\n",
    "    X_train, X_val, y_train, y_val=train_test_split(feature, output, test_size=0.2, random_state=0)\n",
    "    #make all the tensors\n",
    "    X_train=torch.FloatTensor(X_train)\n",
    "    X_val=torch.FloatTensor(X_val)\n",
    "    y_train=torch.FloatTensor(y_train)\n",
    "    y_val=torch.FloatTensor(y_val)\n",
    "\n",
    "    X_test1=torch.FloatTensor(X_test1)\n",
    "    y_test1=torch.FloatTensor(y_test1)\n",
    "    X_test2=torch.FloatTensor(X_test2)\n",
    "    y_test2=torch.FloatTensor(y_test2)\n",
    "    X_test3=torch.FloatTensor(X_test3)\n",
    "    y_test3=torch.FloatTensor(y_test3)\n",
    "\n",
    "\n",
    "    #Instantiate the model\n",
    "    model=NN()\n",
    "    criterion=torch.nn.MSELoss()\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.train()\n",
    "    epoch=1000\n",
    "    loss_arr=[]\n",
    "    loss_val_arr=[]\n",
    "    for epoch in range(epoch):\n",
    "        optimizer.zero_grad()\n",
    "        #Forward pass\n",
    "        y_pred=model(X_train)\n",
    "        #compute loss\n",
    "        loss=criterion(y_pred.squeeze(), y_train)\n",
    "        loss_arr.append(loss.item())\n",
    "        #print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
    "        #Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            y_pred_val=model(X_val)\n",
    "            loss_val=criterion(y_pred_val.squeeze(), y_val)\n",
    "            loss_val_arr.append(loss_val.item())\n",
    "            #print('Epoch {}: val loss: {}'.format(epoch, loss_val.item()))\n",
    "    \n",
    "    #Now evaluate the test set1\n",
    "\n",
    "    y_test1_predicted=[]\n",
    "    y_test1_actual=[]\n",
    "    model.eval()\n",
    "    y_pred1 = model(X_test1)\n",
    "    after_train1 = criterion(y_pred1.squeeze(), y_test1) \n",
    "    #print(torch.sqrt(after_train))\n",
    "    test1_rmse=sqrt(after_train1)\n",
    "    y_test1_predicted.append(y_pred1.tolist())\n",
    "    y_test1_actual.append(y_test1.tolist())\n",
    "    print(y_test1_predicted)\n",
    "\n",
    "    #Now evaluate the test set2\n",
    "\n",
    "    y_test2_predicted=[]\n",
    "    y_test2_actual=[]\n",
    "    model.eval()\n",
    "    y_pred2 = model(X_test2)\n",
    "    after_train2 = criterion(y_pred2.squeeze(), y_test2) \n",
    "    #print(torch.sqrt(after_train))\n",
    "    test2_rmse=sqrt(after_train2)\n",
    "    y_test2_predicted.append(y_pred2.tolist())\n",
    "    y_test2_actual.append(y_test2.tolist())\n",
    "    print(y_test2_predicted)\n",
    "\n",
    "\n",
    "    #Now evaluate the test set2\n",
    "\n",
    "    y_test3_predicted=[]\n",
    "    y_test3_actual=[]\n",
    "    model.eval()\n",
    "    y_pred3 = model(X_test3)\n",
    "    after_train3 = criterion(y_pred3.squeeze(), y_test3) \n",
    "    #print(torch.sqrt(after_train))\n",
    "    test3_rmse=sqrt(after_train3)\n",
    "    y_test3_predicted.append(y_pred3.tolist())\n",
    "    y_test3_actual.append(y_test3.tolist())\n",
    "    print(y_test3_predicted)\n",
    "\n",
    "\n",
    "    return sqrt(loss_arr[-1]), sqrt(loss_val_arr[-1]), test1_rmse, test2_rmse, test3_rmse\n",
    "    \n",
    "\n",
    "result_oob=[]\n",
    "for i in range(0, 1):\n",
    "    result_oob.append(multNNoob(i, Real, Synthetic, df1, df2, df3))\n",
    "\n",
    "dfResultNormal=pd.DataFrame(result_oob, columns=['train_rmse', 'val_rmse', 'oob1_rmse','oob2_rmse', 'oob3_rmse' ])\n",
    "dfResultNormal.describe()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
