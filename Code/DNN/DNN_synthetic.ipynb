{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "q6QwFOr1h33N",
    "outputId": "17d24b04-d754-4e77-d757-c9db7c91d173"
   },
   "outputs": [],
   "source": [
    "# This piece of code is applicable for 80:20 train:test ratio.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "from IPython.display import HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler    \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dropout\n",
    "import csv\n",
    "import concurrent.futures\n",
    "import time\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df=pd.read_csv('MLS-LA-LB-LC-LD-Real-Synthetic80svm.csv') #add (real plus synthetic) datafile name here\n",
    "\n",
    "#separate the real and synthetic dataset\n",
    "Real =df.iloc[:240, :]     # Put the number of real samples, here it is 240\n",
    "Synthetic =df.iloc[240:, :] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(0)      \n",
    "        self.regressor = nn.Sequential(\n",
    "        nn.Linear(153, 33),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(33,150),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(150,400),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(400,168),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(168,128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 1)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.regressor(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def multNN1(seed, df1, df2):\n",
    "    exp_feat=df1.iloc[:, :-1]\n",
    "    exp_ee=df1.iloc[:, -1]\n",
    "    X_exp_train, X_test, y_exp_train, y_test = train_test_split(exp_feat, exp_ee, test_size=0.2, random_state=seed)\n",
    "    #print(X_test.index)\n",
    "    ind_test=X_test.index\n",
    "    df_except_test=pd.concat([X_exp_train, y_exp_train], axis=1)\n",
    "    df_real_syn=pd.concat([df_except_test, df2], axis=0)\n",
    "    \n",
    "    #now separate train and validation set from the combined data i.e. df_real_syn \n",
    "    X_train_val=df_real_syn.iloc[:, :-1].values\n",
    "    y_train_val=df_real_syn.iloc[:, -1].values\n",
    "\n",
    "    #make all the tensors\n",
    "\n",
    "    X_train_val_tensor = torch.FloatTensor(X_train_val)\n",
    "    y_train_val_tensor = torch.FloatTensor(y_train_val)\n",
    "\n",
    "    X_test=torch.FloatTensor(X_test.values)\n",
    "    y_test=torch.FloatTensor(y_test.values)\n",
    "\n",
    "    #Instantiate the model\n",
    "    model=NN()\n",
    "    criterion=torch.nn.MSELoss()\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.train()\n",
    "    epoch=1000\n",
    "    loss_arr=[]\n",
    "    loss_test_arr =[]\n",
    "    train_mae = []\n",
    "    loss_test_mae_arr=[]\n",
    "    y_pred_test_arr =[]\n",
    "    epoch_plot = []\n",
    "\n",
    "    \n",
    "    def my_plot(seed_plot,epochs, train_loss, valid_loss):\n",
    "      plt.figure(figsize=(12,8))\n",
    "      plt.plot(train_loss,'-o')\n",
    "      plt.plot(valid_loss,'-o')\n",
    "      plt.xlabel('epochs')\n",
    "      plt.ylabel('losses')\n",
    "      plt.legend(['train','test'])\n",
    "      plt.title('train vs test loss : seed value ' + str(seed_plot))\n",
    "      plt.show()\n",
    "\n",
    "    for epoch in range(epoch):\n",
    "        optimizer.zero_grad()\n",
    "        #Forward pass\n",
    "        y_pred=model(X_train_val_tensor)\n",
    "        #compute loss\n",
    "        loss=criterion(y_pred.squeeze(), y_train_val_tensor)\n",
    "\n",
    "        #print(loss)\n",
    "        loss_arr.append(loss.item())\n",
    "\n",
    "        tr_mae = sum(abs(x-y) for x,y in zip(y_pred.squeeze(),y_train_val_tensor))/len(X_train_val_tensor)\n",
    "        tr_mae = float(tr_mae)\n",
    "        train_mae.append(tr_mae)\n",
    "\n",
    "        #print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
    "        epoch_plot.append(epoch)\n",
    "        \n",
    "        #Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            y_pred_test=model(X_test)\n",
    "            y_pred_test_arr.append(y_pred_test)\n",
    "            \n",
    "\n",
    "            loss_test=criterion(y_pred_test.squeeze(), y_test)\n",
    "            loss_test_arr.append(loss_test.item())\n",
    "\n",
    "\n",
    "\n",
    "            test_mae = sum(abs(x-y) for x,y in zip(y_pred_test.squeeze(),y_test))/len(X_test)\n",
    "            test_mae = float(test_mae)\n",
    "            loss_test_mae_arr.append(test_mae)\n",
    "          \n",
    "\n",
    "    my_plot(seed, epoch_plot, loss_arr, loss_test_arr)\n",
    "\n",
    "    \n",
    "    y_test_numpy = y_test.numpy()\n",
    "    #print(y_test_numpy)\n",
    "    y_pred_test_numpy = y_pred_test_arr[-1].numpy()\n",
    "    #print(y_pred_test_numpy)\n",
    "\n",
    "    list1= ind_test\n",
    "   \n",
    "    with open('MLS-LA-LB-LC-LD-Real-Synthetic80svm-out.csv', 'a') as csvFile:\n",
    "         writer = csv.writer(csvFile)\n",
    "         writer.writerows(zip(itertools.repeat(seed),list1, y_test_numpy, y_pred_test_numpy))\n",
    "    csvFile.close()\n",
    "\n",
    "    return seed, sqrt(loss_arr[-1]), sqrt(loss_test_arr[-1])\n",
    "\n",
    "\n",
    "\n",
    "result=[]\n",
    "for i in range(0,10000,100):\n",
    "    print('seed = ' + str(i))\n",
    "    result.append(multNN1(i,Real, Synthetic))\n",
    "\n",
    "\n",
    "dfResultNormal=pd.DataFrame(result, columns=['seed', 'train_rmse',  'test_rmse',])\n",
    "\n",
    "dfResultNormal.to_csv('MLS-LA-LB-LC-LD-Real-Synthetic80svm-Result.csv')\n",
    "\n",
    "\n",
    "print(dfResultNormal.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fl7oE3ncnEgT"
   },
   "outputs": [],
   "source": [
    "# This piece of code is applicable for 64:16:20 train:validation:test ratio.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "from IPython.display import HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler    \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dropout\n",
    "import csv\n",
    "import concurrent.futures\n",
    "import time\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df=pd.read_csv('MLS-LA-LB-LC-LD-Real-Synthetic80svm.csv') #add (real plus synthetic) datafile name here\n",
    "\n",
    "#separate the real and synthetic dataset\n",
    "Real =df.iloc[:240, :]          # Put the number of real samples, here it is 240\n",
    "Synthetic =df.iloc[240:, :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(0)      \n",
    "        self.regressor = nn.Sequential(\n",
    "        nn.Linear(153, 33),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(33,150),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(150,400),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(400,168),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(168,128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 1)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.regressor(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def multNN1(seed, df1, df2):\n",
    "    exp_feat=df1.iloc[:, :-1]\n",
    "    exp_ee=df1.iloc[:, -1]\n",
    "    X_exp_train, X_test, y_exp_train, y_test = train_test_split(exp_feat, exp_ee, test_size=0.2, random_state=seed)\n",
    "    #print(X_test.index)\n",
    "    ind_val=X_test.index\n",
    "    df_except_test=pd.concat([X_exp_train, y_exp_train], axis=1)\n",
    "    df_real_syn=pd.concat([df_except_test, df2], axis=0)\n",
    "    #now separate train and validation set from the combined data i.e. df_real_syn\n",
    "    X_train_val=df_real_syn.iloc[:, :-1].values\n",
    "    y_train_val=df_real_syn.iloc[:, -1].values\n",
    "    X_train, X_val, y_train, y_val=train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=0)\n",
    "    #make all the tensors\n",
    "    X_train=torch.FloatTensor(X_train)\n",
    "    X_val=torch.FloatTensor(X_val)\n",
    "    y_train=torch.FloatTensor(y_train)\n",
    "    y_val=torch.FloatTensor(y_val)\n",
    "    X_test=torch.FloatTensor(X_test.values)\n",
    "    y_test=torch.FloatTensor(y_test.values)\n",
    "    #Instantiate the model\n",
    "    model=NN()\n",
    "    criterion=torch.nn.MSELoss()\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.train()\n",
    "    epoch=1000\n",
    "    loss_arr=[]\n",
    "    loss_val_arr=[]\n",
    "    \n",
    "    epoch_plot = []\n",
    "\n",
    "    \n",
    "    def my_plot(seed_plot, epochs, train_loss, valid_loss):\n",
    "      plt.plot(train_loss,'-o')\n",
    "      plt.plot(valid_loss,'-o')\n",
    "      plt.xlabel('epochs')\n",
    "      plt.ylabel('losses')\n",
    "      plt.legend(['train','valid'])\n",
    "      plt.title('train vs valid loss')\n",
    "      plt.title('train vs valid loss : seed value ' + str(seed_plot))\n",
    "      plt.show()\n",
    "\n",
    "    for epoch in range(epoch):\n",
    "        optimizer.zero_grad()\n",
    "        #Forward pass\n",
    "        y_pred=model(X_train)\n",
    "        #compute loss\n",
    "        loss=criterion(y_pred.squeeze(), y_train)\n",
    "        loss_arr.append(loss.item())\n",
    "        #print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
    "        epoch_plot.append(epoch)\n",
    "        \n",
    "        #Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            y_pred_val=model(X_val)\n",
    "            loss_val=criterion(y_pred_val.squeeze(), y_val)\n",
    "            loss_val_arr.append(loss_val.item())\n",
    "            #print('Epoch {}: val loss: {}'.format(epoch, loss_val.item()))\n",
    "    #print(loss_arr)\n",
    "    #print(loss_val_arr)\n",
    "    #print(epoch_plot)\n",
    "    my_plot(seed, epoch_plot, loss_arr, loss_val_arr)\n",
    "    #Now evaluate the test set\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    after_train = criterion(y_pred.squeeze(), y_test) \n",
    "    #print(torch.sqrt(after_train))\n",
    "    test_rmse=sqrt(after_train)\n",
    "    list1= ind_val\n",
    "\n",
    "    with open('MLS-LA-LB-LC-LD-Real-Synthetic80svm-out.csv', 'a') as csvFile:\n",
    "         writer = csv.writer(csvFile)\n",
    "         writer.writerows(zip(itertools.repeat(seed),list1, y_test, y_pred))\n",
    "    csvFile.close()\n",
    "\n",
    "    return seed, sqrt(loss_arr[-1]), sqrt(loss_val_arr[-1]), test_rmse\n",
    "\n",
    "\n",
    "\n",
    "result=[]\n",
    "for i in range(0,10000,100):\n",
    "    print('seed = ' + str(i))\n",
    "    result.append(multNN1(i,Real, Synthetic))\n",
    "\n",
    "\n",
    "dfResultNormal=pd.DataFrame(result, columns=['seed', 'train_rmse', 'val_rmse', 'test_rmse'])\n",
    "\n",
    "dfResultNormal.describe()\n",
    "dfResultNormal.to_csv('MLS-LA-LB-LC-LD-Real-Synthetic80svm-Result.csv')\n",
    "\n",
    "\n",
    "print(dfResultNormal.describe())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
